{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EMBC2020: Prediction of Length of Stay on the Intensive Care Unit based on Bayesian Neural Networks\n",
    "1.Dataset: \n",
    "  1)eICU-CRD, https://physionet.org/content/eicu-crd/2.0/   and    https://eicu-crd.mit.edu/ \n",
    "  2)Abstract: The eICU Collaborative Research Database is a multi-center database comprising deidentified health data associated with                over 200,000 admissions to ICUs across the United States between 2014-2015. The database includes vital sign                        measurements, care plan documentation, severity of illness measures, diagnosis information, and treatment information.                Data is collected through the Philips eICU program, a critical care telehealth program that delivers information to                  caregivers at the bedside. \n",
    "  3)Table used: apacheApsVar, apachePredVar, apachePatientResult\n",
    "  \n",
    "2.Task: \n",
    "  1)Apache(Acute Physiology and Chronic Health Evaluation) IV scoring system have been used widely in the intensive care unit(ICU).\n",
    "  2)Critical care medicine Journal-2006: Acute Physiology and Chronic Health Evaluation (APACHE) IV: hospital mortality assessment for todayâ€™s critically ill patients.\n",
    "  3)Predict length of stay (los) and Mortality, considering the degree of disease but not directly mortality.\n",
    "  \n",
    "3.Model: \n",
    "  The performance of BNN,DNN,LS+L1,RF on anti-overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "The shape of testset is : 27248,53\n",
      "MAE Score of LS+L2 on eICU-CRD dataset is : 2.010006863171179\n",
      "R^2 Score of LS+L2 on eICU-CRD dataset is : 0.09309768755163184\n",
      "EV Score of LS+L2 on eICU-CRD dataset is : 0.09312384144652552\n",
      "MAE Score of LS+L2 on eICU-CRD trainset is : 1.9892872461008608\n",
      "R^2 Score of LS+L2 on eICU-CRD trainset is : 0.11570251878989302\n",
      "EV Score of LS+L2 on eICU-CRD trainset is : 0.11570251879049842\n"
     ]
    }
   ],
   "source": [
    "#Ridge anti-overfitting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#1 load dataset\n",
    "#trainset\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "#testset\n",
    "teststet = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "print ('The shape of testset is : %d,%d'%(teststet.shape[0],teststet.shape[1]))\n",
    "\n",
    "#2 LR+L1 training\n",
    "X = trainset.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y = trainset['actualiculos']#label\n",
    "param_grid = {'fit_intercept':[True,False],'alpha':[0.01,0.05,0.1,0.5]}\n",
    "clf = linear_model.Ridge(normalize=False,random_state=0) #max_iter\n",
    "grid_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_clf.fit(X, y.ravel())\n",
    "\n",
    "#4.3 prediction and evaluation\n",
    "X_test = teststet.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y_test = teststet['actualiculos']#label \n",
    "y_pred = grid_clf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE Score of LS+L2 on eICU-CRD dataset is :\", mae)  \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score of LS+L2 on eICU-CRD dataset is :\", r2) \n",
    "ev = explained_variance_score(y_test, y_pred)\n",
    "print(\"EV Score of LS+L2 on eICU-CRD dataset is :\", ev)\n",
    "#trainset\n",
    "y_pred_tr = grid_clf.predict(X)\n",
    "mae = mean_absolute_error(y, y_pred_tr)\n",
    "print(\"MAE Score of LS+L2 on eICU-CRD trainset is :\", mae)  \n",
    "r2 = r2_score(y, y_pred_tr)\n",
    "print(\"R^2 Score of LS+L2 on eICU-CRD trainset is :\", r2) \n",
    "ev = explained_variance_score(y, y_pred_tr)\n",
    "print(\"EV Score of LS+L2 on eICU-CRD trainset is :\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "100 / 109 : loss = 117.19596862792969\n",
      "100 / 109 : loss = 42.032379150390625260742188\n",
      "100 / 109 : loss = 28.67951011657715020019531\n",
      "100 / 109 : loss = 23.9923191070556643515625\n",
      "100 / 109 : loss = 21.177944183349612381591797\n",
      "100 / 109 : loss = 19.33827209472656200366211\n",
      "100 / 109 : loss = 18.082189559936523302734375\n",
      "100 / 109 : loss = 17.193670272827155791015625\n",
      "100 / 109 : loss = 16.54924774169922921875\n",
      "100 / 109 : loss = 16.074808120727544012451172\n",
      "100 / 109 : loss = 15.723123550415039506835938\n",
      "100 / 109 : loss = 15.462282180786133409973145\n",
      "100 / 109 : loss = 15.269572257995605306396484\n",
      "100 / 109 : loss = 15.128169059753418700073242\n",
      "100 / 109 : loss = 15.025276184082031871276855\n",
      "100 / 109 : loss = 14.951022148132324326538086\n",
      "100 / 109 : loss = 14.897807121276855020385742\n",
      "100 / 109 : loss = 14.85982704162597700213623\n",
      "100 / 109 : loss = 14.832713127136231952514648\n",
      "100 / 109 : loss = 14.813230514526367242675781\n",
      "100 / 109 : loss = 14.799049377441406823913574\n",
      "100 / 109 : loss = 14.788507461547852032714844\n",
      "100 / 109 : loss = 14.780462265014648245666504\n",
      "100 / 109 : loss = 14.774133682250977071105957\n",
      "100 / 109 : loss = 14.769002914428711224487305\n",
      "100 / 109 : loss = 14.76473045349121171685791\n",
      "100 / 109 : loss = 14.761097908020021460266113\n",
      "100 / 109 : loss = 14.757957458496094000976562\n",
      "100 / 109 : loss = 14.755218505859375345336914\n",
      "100 / 109 : loss = 14.75281524658203134954834\n",
      "100 / 109 : loss = 14.750703811645508970458984\n",
      "100 / 109 : loss = 14.748850822448730543518066\n",
      "100 / 109 : loss = 14.747232437133789894592285\n",
      "100 / 109 : loss = 14.745823860168457737731934\n",
      "100 / 109 : loss = 14.744604110717773879638672\n",
      "100 / 109 : loss = 14.743557929992676524780273\n",
      "Mean loss in this epoch is: 14.049947738647461"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "from math import sqrt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#1.1.1 design model\n",
    "class TF_DNNRegressor_eICU:\n",
    "    def __init__(self, lr=0.001, dim=52, num_class=1, batchSize=1000):\n",
    "        #global parameters\n",
    "        self.lr = lr\n",
    "        self.dim = dim # dimensions of sample\n",
    "        self.num_class = num_class #output \n",
    "        self.hidden_layers = [16, 4]\n",
    "        #set network structure\n",
    "        self.add_placeholders()\n",
    "        self.add_weight()\n",
    "        self.add_model()\n",
    "        self.add_loss()\n",
    "        self.add_optimizer()\n",
    "        self.init_sess()\n",
    "        \n",
    "    def add_placeholders(self):    \n",
    "        self.X_input = tf.placeholder(\"float\", [None, self.dim])\n",
    "        self.Y_input = tf.placeholder(\"float\", [None, self.num_class])\n",
    "        self.keep_prob = tf.placeholder(tf.float32)  \n",
    "    \n",
    "    def add_weight(self):\n",
    "        # Store layers weight & bias\n",
    "        #init_uniform = tf.random_uniform_initializer(minval=0, maxval=1, seed=None, dtype=tf.float32)\n",
    "        self.weights = {\n",
    "            'w1': tf.Variable(tf.random_normal([self.dim, self.hidden_layers[0]])),\n",
    "            'w2': tf.Variable(tf.random_normal([self.hidden_layers[0], self.hidden_layers[1]])),\n",
    "            #'w3': tf.Variable(tf.random_normal([self.hidden_layers[1], self.hidden_layers[2]])),\n",
    "            #'w4': tf.Variable(tf.random_normal([self.hidden_layers[2], self.hidden_layers[3]])),\n",
    "            'wout': tf.Variable(tf.random_normal([self.hidden_layers[1], self.num_class]))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([self.hidden_layers[0]])),\n",
    "            'b2': tf.Variable(tf.random_normal([self.hidden_layers[1]])),\n",
    "            #'b3': tf.Variable(tf.random_normal([self.hidden_layers[2]])),\n",
    "            #'b4': tf.Variable(tf.random_normal([self.hidden_layers[3]])),\n",
    "            'bout': tf.Variable(tf.random_normal([self.num_class]))\n",
    "        }\n",
    "        \n",
    "    def add_model(self):\n",
    "        # Hidden fully connected layer with 1024 neurons\n",
    "        layer_1 =  tf.add(tf.matmul(self.X_input, self.weights['w1']), self.biases['b1']) \n",
    "        # Hidden fully connected layer with 256 neurons\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, self.weights['w2']), self.biases['b2']) \n",
    "        # Hidden fully connected layer with 128 neurons\n",
    "        #layer_3 =  tf.add(tf.matmul(layer_2, self.weights['w3']), self.biases['b3']) \n",
    "        # Hidden fully connected layer with 32 neurons \n",
    "        #layer_4 =  tf.add(tf.matmul(layer_3, self.weights['w4']), self.biases['b4']) \n",
    "        # Output fully connected layer with a neuron for each class\n",
    "        out_layer =tf.matmul(layer_2, self.weights['wout']) + self.biases['bout'] \n",
    "        self.Y_output =  out_layer\n",
    "    \n",
    "    def add_loss(self):\n",
    "         self.loss = tf.losses.mean_squared_error( self.Y_input , self.Y_output ) \n",
    "            \n",
    "    def add_optimizer(self):\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_step = optimizer.minimize(self.loss)\n",
    "        \n",
    "    def init_sess(self):\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        self.config.allow_soft_placement = True\n",
    "        #self.config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "        self.sess = tf.Session(config=self.config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#1.1.2 train model\n",
    "#load trainset\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "#min-max scale the continous features\n",
    "ss = MinMaxScaler()\n",
    "scale_features = ['ph', 'creatinine', 'albumin','diagnosis']\n",
    "trainset[scale_features] = ss.fit_transform(trainset[scale_features])\n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "X = trainset.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "Y = trainset['actualiculos'].to_frame()#label, from series to array\n",
    "#define model\n",
    "tf_model = TF_DNNRegressor_eICU()\n",
    "#set paramete\n",
    "verbose = 10\n",
    "batchSize=1000\n",
    "num_batches = X.shape[0] // batchSize + 1 \n",
    "pre_loss = 0.0\n",
    "while True:#convergence\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([X.shape[0], (i+1)*batchSize])\n",
    "        X_batch = X[min_idx: max_idx]\n",
    "        Y_batch = Y[min_idx: max_idx]\n",
    "        #_, tmp_loss, y_out = tf_model.sess.run([tf_model.train_step, tf_model.loss, tf_model.Y_output], \n",
    "        #                                 feed_dict={tf_model.X_input: X_batch,tf_model.Y_input: Y_batch})\n",
    "        _, tmp_loss,  = tf_model.sess.run([tf_model.train_step, tf_model.loss], \n",
    "                                         feed_dict={tf_model.X_input: X_batch,tf_model.Y_input: Y_batch, tf_model.keep_prob: 0.6})\n",
    "        losses.append(tmp_loss)\n",
    "        if verbose and i % verbose == 0:\n",
    "            sys.stdout.write('\\r{} / {} : loss = {}'.format(i, num_batches, np.mean(losses[-verbose:])))\n",
    "            sys.stdout.flush()\n",
    "    sys.stdout.write(\"\\nMean loss in this epoch is: {}\".format( np.mean(losses) ))\n",
    "    sys.stdout.flush()\n",
    "    #whether convergence\n",
    "    if abs( np.mean(losses) - pre_loss)<0.001:\n",
    "        break\n",
    "    else:\n",
    "        pre_loss = np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of testset is : 27248,53\n",
      "MAE Score of DNN on eICU-CRD dataset is : 2.0309516431815196\n",
      "RMSE Score of DNN on eICU-CRD dataset is : 4.231293240333169\n",
      "R^2 Score of DNN on eICU-CRD dataset is : 0.09257889620076531\n",
      "EV Score of DNN on eICU-CRD dataset is : 0.09262862172546693\n",
      "MAE Score of RandomForest on eICU-CRD trainset is : 2.0105510213615463\n",
      "R^2 Score of RandomForest on eICU-CRD trainset is : 0.11467417707790517\n",
      "EV Score of RandomForest on eICU-CRD trainset is : 0.11484501810532255\n"
     ]
    }
   ],
   "source": [
    "#1.1.3  prediction and evaluation\n",
    "#testset\n",
    "teststet = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "teststet[scale_features] = ss.fit_transform(teststet[scale_features])\n",
    "print ('The shape of testset is : %d,%d'%(teststet.shape[0],teststet.shape[1]))\n",
    "X_test = teststet.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y_test = teststet['actualiculos'].to_frame()#label \n",
    "#prediction\n",
    "y_pred = tf_model.sess.run(tf_model.Y_output, feed_dict={tf_model.X_input: X_test,tf_model.Y_input: y_test, tf_model.keep_prob: 1}) \n",
    "#y_pred = tf_model.sess.run(tf.nn.relu(y_pred))\n",
    "#np.set_printoptions(precision=4)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE Score of DNN on eICU-CRD dataset is :\", mae)  \n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE Score of DNN on eICU-CRD dataset is :\", rmse)  \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score of DNN on eICU-CRD dataset is :\", r2) \n",
    "ev = explained_variance_score(y_test, y_pred)\n",
    "print(\"EV Score of DNN on eICU-CRD dataset is :\", ev)\n",
    "\n",
    "#trainset\n",
    "y_pred_tr = tf_model.sess.run(tf_model.Y_output, feed_dict={tf_model.X_input: X,tf_model.Y_input: Y, tf_model.keep_prob: 1}) \n",
    "mae = mean_absolute_error(Y, y_pred_tr)\n",
    "print(\"MAE Score of RandomForest on eICU-CRD trainset is :\", mae)  \n",
    "r2 = r2_score(Y, y_pred_tr)\n",
    "print(\"R^2 Score of RandomForest on eICU-CRD trainset is :\", r2) \n",
    "ev = explained_variance_score(Y, y_pred_tr)\n",
    "print(\"EV Score of RandomForest on eICU-CRD trainset is :\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/data/tmpexec/eICU_DNN_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f647b9a6bd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f64770bc410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f64770bc410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f64770bc410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f64770bc410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770bc690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770bc690>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770bc690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770bc690>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bce50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bce50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bccd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770bccd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770ee3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770ee3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770ee3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f64770ee3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /data/tmpexec/eICU_DNN_model/model.ckpt-30000\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /data/tmpexec/eICU_DNN_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1006.29846, step = 30000\n",
      "INFO:tensorflow:global_step/sec: 45.4205\n",
      "INFO:tensorflow:loss = 2431.926, step = 30100 (2.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.4375\n",
      "INFO:tensorflow:loss = 1007.73895, step = 30200 (2.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0533\n",
      "INFO:tensorflow:loss = 1164.8701, step = 30300 (2.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4829\n",
      "INFO:tensorflow:loss = 642.27075, step = 30400 (2.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.2789\n",
      "INFO:tensorflow:loss = 577.66223, step = 30500 (2.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7091\n",
      "INFO:tensorflow:loss = 638.9068, step = 30600 (2.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9175\n",
      "INFO:tensorflow:loss = 1031.2961, step = 30700 (2.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9956\n",
      "INFO:tensorflow:loss = 902.1257, step = 30800 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.485\n",
      "INFO:tensorflow:loss = 644.98413, step = 30900 (2.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8366\n",
      "INFO:tensorflow:loss = 2542.3086, step = 31000 (2.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9416\n",
      "INFO:tensorflow:loss = 4243.043, step = 31100 (2.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7497\n",
      "INFO:tensorflow:loss = 2172.0269, step = 31200 (2.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3622\n",
      "INFO:tensorflow:loss = 2450.5835, step = 31300 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4556\n",
      "INFO:tensorflow:loss = 2894.9697, step = 31400 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.578\n",
      "INFO:tensorflow:loss = 1560.6648, step = 31500 (2.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1694\n",
      "INFO:tensorflow:loss = 1568.0737, step = 31600 (2.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0823\n",
      "INFO:tensorflow:loss = 750.3446, step = 31700 (2.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0896\n",
      "INFO:tensorflow:loss = 644.8659, step = 31800 (2.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.2425\n",
      "INFO:tensorflow:loss = 1353.2594, step = 31900 (2.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4864\n",
      "INFO:tensorflow:loss = 998.6036, step = 32000 (2.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1628\n",
      "INFO:tensorflow:loss = 861.08826, step = 32100 (2.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9685\n",
      "INFO:tensorflow:loss = 910.3483, step = 32200 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3178\n",
      "INFO:tensorflow:loss = 1825.8441, step = 32300 (2.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7552\n",
      "INFO:tensorflow:loss = 1057.2048, step = 32400 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5194\n",
      "INFO:tensorflow:loss = 695.0856, step = 32500 (2.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.044\n",
      "INFO:tensorflow:loss = 2315.0586, step = 32600 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5908\n",
      "INFO:tensorflow:loss = 3540.9836, step = 32700 (2.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5576\n",
      "INFO:tensorflow:loss = 1248.6864, step = 32800 (1.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4143\n",
      "INFO:tensorflow:loss = 1183.9075, step = 32900 (2.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.688\n",
      "INFO:tensorflow:loss = 1641.0781, step = 33000 (2.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4181\n",
      "INFO:tensorflow:loss = 4578.796, step = 33100 (2.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0924\n",
      "INFO:tensorflow:loss = 1122.2034, step = 33200 (2.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4034\n",
      "INFO:tensorflow:loss = 1286.0767, step = 33300 (2.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5193\n",
      "INFO:tensorflow:loss = 898.80237, step = 33400 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.9431\n",
      "INFO:tensorflow:loss = 1366.9023, step = 33500 (2.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.776\n",
      "INFO:tensorflow:loss = 1647.5872, step = 33600 (1.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.86\n",
      "INFO:tensorflow:loss = 1416.8782, step = 33700 (2.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5256\n",
      "INFO:tensorflow:loss = 1612.5427, step = 33800 (2.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0089\n",
      "INFO:tensorflow:loss = 2347.6604, step = 33900 (2.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7925\n",
      "INFO:tensorflow:loss = 4575.6406, step = 34000 (1.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5303\n",
      "INFO:tensorflow:loss = 832.20416, step = 34100 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7108\n",
      "INFO:tensorflow:loss = 1385.148, step = 34200 (2.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7916\n",
      "INFO:tensorflow:loss = 2103.6135, step = 34300 (2.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4414\n",
      "INFO:tensorflow:loss = 2294.066, step = 34400 (2.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4707\n",
      "INFO:tensorflow:loss = 535.165, step = 34500 (2.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8844\n",
      "INFO:tensorflow:loss = 2131.4817, step = 34600 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0184\n",
      "INFO:tensorflow:loss = 1565.1936, step = 34700 (2.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.753\n",
      "INFO:tensorflow:loss = 3403.7979, step = 34800 (2.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0539\n",
      "INFO:tensorflow:loss = 1345.7869, step = 34900 (2.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6221\n",
      "INFO:tensorflow:loss = 11556.938, step = 35000 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6653\n",
      "INFO:tensorflow:loss = 1458.3551, step = 35100 (2.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6915\n",
      "INFO:tensorflow:loss = 2005.9111, step = 35200 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5204\n",
      "INFO:tensorflow:loss = 1445.9346, step = 35300 (1.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1506\n",
      "INFO:tensorflow:loss = 886.1576, step = 35400 (2.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.097\n",
      "INFO:tensorflow:loss = 2296.2407, step = 35500 (1.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8793\n",
      "INFO:tensorflow:loss = 3880.9456, step = 35600 (2.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2027\n",
      "INFO:tensorflow:loss = 2118.0981, step = 35700 (1.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3589\n",
      "INFO:tensorflow:loss = 840.9414, step = 35800 (1.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0803\n",
      "INFO:tensorflow:loss = 556.656, step = 35900 (2.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1628\n",
      "INFO:tensorflow:loss = 1345.9624, step = 36000 (2.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8776\n",
      "INFO:tensorflow:loss = 2409.8523, step = 36100 (1.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.101\n",
      "INFO:tensorflow:loss = 542.2115, step = 36200 (2.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6053\n",
      "INFO:tensorflow:loss = 2192.2546, step = 36300 (2.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6598\n",
      "INFO:tensorflow:loss = 1324.9565, step = 36400 (2.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0995\n",
      "INFO:tensorflow:loss = 7171.735, step = 36500 (2.080 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 49.3305\n",
      "INFO:tensorflow:loss = 2839.2075, step = 36600 (2.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8592\n",
      "INFO:tensorflow:loss = 1868.3276, step = 36700 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6779\n",
      "INFO:tensorflow:loss = 691.3883, step = 36800 (2.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8434\n",
      "INFO:tensorflow:loss = 1386.9429, step = 36900 (2.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.407\n",
      "INFO:tensorflow:loss = 1233.8008, step = 37000 (2.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4738\n",
      "INFO:tensorflow:loss = 2187.7734, step = 37100 (2.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3505\n",
      "INFO:tensorflow:loss = 1098.9229, step = 37200 (2.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0654\n",
      "INFO:tensorflow:loss = 1101.0891, step = 37300 (1.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6586\n",
      "INFO:tensorflow:loss = 1959.6177, step = 37400 (2.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.3643\n",
      "INFO:tensorflow:loss = 587.26306, step = 37500 (2.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2296\n",
      "INFO:tensorflow:loss = 852.3953, step = 37600 (1.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4297\n",
      "INFO:tensorflow:loss = 2252.6711, step = 37700 (2.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5389\n",
      "INFO:tensorflow:loss = 1170.4938, step = 37800 (1.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1439\n",
      "INFO:tensorflow:loss = 749.45184, step = 37900 (1.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7276\n",
      "INFO:tensorflow:loss = 1143.2574, step = 38000 (2.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0528\n",
      "INFO:tensorflow:loss = 774.7, step = 38100 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.378\n",
      "INFO:tensorflow:loss = 1330.5029, step = 38200 (2.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4379\n",
      "INFO:tensorflow:loss = 931.57837, step = 38300 (2.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1842\n",
      "INFO:tensorflow:loss = 1174.1475, step = 38400 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0487\n",
      "INFO:tensorflow:loss = 1985.6073, step = 38500 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3385\n",
      "INFO:tensorflow:loss = 2755.1907, step = 38600 (2.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.908\n",
      "INFO:tensorflow:loss = 1302.9452, step = 38700 (2.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.138\n",
      "INFO:tensorflow:loss = 1356.3734, step = 38800 (2.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.7197\n",
      "INFO:tensorflow:loss = 1731.0116, step = 38900 (1.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6847\n",
      "INFO:tensorflow:loss = 1969.8029, step = 39000 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.5244\n",
      "INFO:tensorflow:loss = 2431.4888, step = 39100 (1.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.659\n",
      "INFO:tensorflow:loss = 2010.3334, step = 39200 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3495\n",
      "INFO:tensorflow:loss = 876.41974, step = 39300 (2.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3147\n",
      "INFO:tensorflow:loss = 1211.8508, step = 39400 (2.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.8872\n",
      "INFO:tensorflow:loss = 1487.5022, step = 39500 (1.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3478\n",
      "INFO:tensorflow:loss = 708.534, step = 39600 (2.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8792\n",
      "INFO:tensorflow:loss = 1657.3745, step = 39700 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8554\n",
      "INFO:tensorflow:loss = 1049.2184, step = 39800 (2.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9473\n",
      "INFO:tensorflow:loss = 1094.9882, step = 39900 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7635\n",
      "INFO:tensorflow:loss = 548.61316, step = 40000 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0834\n",
      "INFO:tensorflow:loss = 1818.0952, step = 40100 (1.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.514\n",
      "INFO:tensorflow:loss = 912.25366, step = 40200 (2.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9975\n",
      "INFO:tensorflow:loss = 1967.7747, step = 40300 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1859\n",
      "INFO:tensorflow:loss = 2671.7102, step = 40400 (2.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.842\n",
      "INFO:tensorflow:loss = 1494.7683, step = 40500 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4512\n",
      "INFO:tensorflow:loss = 2049.2139, step = 40600 (2.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.2045\n",
      "INFO:tensorflow:loss = 689.8933, step = 40700 (1.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.763\n",
      "INFO:tensorflow:loss = 1494.7372, step = 40800 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1491\n",
      "INFO:tensorflow:loss = 964.16693, step = 40900 (2.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0611\n",
      "INFO:tensorflow:loss = 1569.8093, step = 41000 (2.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5002\n",
      "INFO:tensorflow:loss = 833.8937, step = 41100 (2.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2116\n",
      "INFO:tensorflow:loss = 636.6869, step = 41200 (2.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4223\n",
      "INFO:tensorflow:loss = 854.8442, step = 41300 (2.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7193\n",
      "INFO:tensorflow:loss = 1514.5117, step = 41400 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0306\n",
      "INFO:tensorflow:loss = 872.7254, step = 41500 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3477\n",
      "INFO:tensorflow:loss = 1196.5104, step = 41600 (2.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8339\n",
      "INFO:tensorflow:loss = 1211.5125, step = 41700 (2.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1151\n",
      "INFO:tensorflow:loss = 2357.7234, step = 41800 (1.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3134\n",
      "INFO:tensorflow:loss = 890.7943, step = 41900 (2.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0373\n",
      "INFO:tensorflow:loss = 1108.3046, step = 42000 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0471\n",
      "INFO:tensorflow:loss = 1225.8167, step = 42100 (2.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1539\n",
      "INFO:tensorflow:loss = 470.02765, step = 42200 (2.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.9403\n",
      "INFO:tensorflow:loss = 1842.6312, step = 42300 (2.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7369\n",
      "INFO:tensorflow:loss = 1550.2827, step = 42400 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2441\n",
      "INFO:tensorflow:loss = 1523.0203, step = 42500 (2.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3117\n",
      "INFO:tensorflow:loss = 1256.5175, step = 42600 (1.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1562\n",
      "INFO:tensorflow:loss = 978.8448, step = 42700 (2.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4081\n",
      "INFO:tensorflow:loss = 1436.5874, step = 42800 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7123\n",
      "INFO:tensorflow:loss = 1231.9572, step = 42900 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8748\n",
      "INFO:tensorflow:loss = 775.7605, step = 43000 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1301\n",
      "INFO:tensorflow:loss = 1136.3633, step = 43100 (2.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.244\n",
      "INFO:tensorflow:loss = 7838.0034, step = 43200 (1.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6316\n",
      "INFO:tensorflow:loss = 1114.4408, step = 43300 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4634\n",
      "INFO:tensorflow:loss = 753.66187, step = 43400 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7242\n",
      "INFO:tensorflow:loss = 1835.7273, step = 43500 (2.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3817\n",
      "INFO:tensorflow:loss = 1826.0675, step = 43600 (2.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3316\n",
      "INFO:tensorflow:loss = 978.3746, step = 43700 (1.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4262\n",
      "INFO:tensorflow:loss = 3030.7686, step = 43800 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7152\n",
      "INFO:tensorflow:loss = 1122.0586, step = 43900 (2.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4306\n",
      "INFO:tensorflow:loss = 880.79065, step = 44000 (2.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0877\n",
      "INFO:tensorflow:loss = 1517.9541, step = 44100 (2.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2898\n",
      "INFO:tensorflow:loss = 933.86475, step = 44200 (2.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7969\n",
      "INFO:tensorflow:loss = 1021.6537, step = 44300 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9963\n",
      "INFO:tensorflow:loss = 2073.0874, step = 44400 (1.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.7679\n",
      "INFO:tensorflow:loss = 1972.0039, step = 44500 (2.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5973\n",
      "INFO:tensorflow:loss = 1478.8003, step = 44600 (2.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6401\n",
      "INFO:tensorflow:loss = 928.4646, step = 44700 (1.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1799.4369, step = 44800 (2.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5439\n",
      "INFO:tensorflow:loss = 5218.819, step = 44900 (2.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3478\n",
      "INFO:tensorflow:loss = 2307.9275, step = 45000 (2.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4064\n",
      "INFO:tensorflow:loss = 1622.9044, step = 45100 (2.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2794\n",
      "INFO:tensorflow:loss = 880.43604, step = 45200 (2.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1769\n",
      "INFO:tensorflow:loss = 11720.0205, step = 45300 (2.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6671\n",
      "INFO:tensorflow:loss = 1298.5867, step = 45400 (2.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8057\n",
      "INFO:tensorflow:loss = 2862.152, step = 45500 (2.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1388\n",
      "INFO:tensorflow:loss = 2928.2598, step = 45600 (1.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7867\n",
      "INFO:tensorflow:loss = 1163.9479, step = 45700 (2.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1142\n",
      "INFO:tensorflow:loss = 1068.2323, step = 45800 (2.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.431\n",
      "INFO:tensorflow:loss = 910.42065, step = 45900 (2.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4036\n",
      "INFO:tensorflow:loss = 1222.8739, step = 46000 (2.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7994\n",
      "INFO:tensorflow:loss = 909.1387, step = 46100 (2.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8146\n",
      "INFO:tensorflow:loss = 1134.1357, step = 46200 (2.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6406\n",
      "INFO:tensorflow:loss = 1997.5198, step = 46300 (2.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8603\n",
      "INFO:tensorflow:loss = 1147.7227, step = 46400 (2.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3005\n",
      "INFO:tensorflow:loss = 1074.9105, step = 46500 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7287\n",
      "INFO:tensorflow:loss = 1681.2626, step = 46600 (2.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1721\n",
      "INFO:tensorflow:loss = 1076.9602, step = 46700 (2.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0637\n",
      "INFO:tensorflow:loss = 4181.749, step = 46800 (1.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7959\n",
      "INFO:tensorflow:loss = 1381.8289, step = 46900 (2.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3905\n",
      "INFO:tensorflow:loss = 889.07446, step = 47000 (2.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.1618\n",
      "INFO:tensorflow:loss = 1973.45, step = 47100 (2.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.392\n",
      "INFO:tensorflow:loss = 1714.2668, step = 47200 (2.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0142\n",
      "INFO:tensorflow:loss = 3435.3955, step = 47300 (2.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5744\n",
      "INFO:tensorflow:loss = 1773.3698, step = 47400 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0772\n",
      "INFO:tensorflow:loss = 1972.8381, step = 47500 (2.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.515\n",
      "INFO:tensorflow:loss = 1220.8894, step = 47600 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7482\n",
      "INFO:tensorflow:loss = 807.4502, step = 47700 (2.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.6712\n",
      "INFO:tensorflow:loss = 1657.1492, step = 47800 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5\n",
      "INFO:tensorflow:loss = 1427.7017, step = 47900 (2.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0368\n",
      "INFO:tensorflow:loss = 726.7501, step = 48000 (2.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5503\n",
      "INFO:tensorflow:loss = 1785.4675, step = 48100 (2.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.0348\n",
      "INFO:tensorflow:loss = 1109.7192, step = 48200 (2.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.6849\n",
      "INFO:tensorflow:loss = 635.67303, step = 48300 (2.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2632\n",
      "INFO:tensorflow:loss = 1736.7354, step = 48400 (2.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.4513\n",
      "INFO:tensorflow:loss = 1278.1321, step = 48500 (2.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8894\n",
      "INFO:tensorflow:loss = 906.88354, step = 48600 (2.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.5077\n",
      "INFO:tensorflow:loss = 778.4789, step = 48700 (2.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.2441\n",
      "INFO:tensorflow:loss = 1113.7152, step = 48800 (2.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.321\n",
      "INFO:tensorflow:loss = 810.6855, step = 48900 (2.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.3536\n",
      "INFO:tensorflow:loss = 2124.429, step = 49000 (2.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9739\n",
      "INFO:tensorflow:loss = 1019.09784, step = 49100 (2.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1841\n",
      "INFO:tensorflow:loss = 1479.052, step = 49200 (2.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4709\n",
      "INFO:tensorflow:loss = 2171.2573, step = 49300 (2.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8431\n",
      "INFO:tensorflow:loss = 2462.6511, step = 49400 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2897\n",
      "INFO:tensorflow:loss = 933.53125, step = 49500 (1.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1927\n",
      "INFO:tensorflow:loss = 1180.6707, step = 49600 (1.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7153\n",
      "INFO:tensorflow:loss = 1340.5623, step = 49700 (2.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.6051\n",
      "INFO:tensorflow:loss = 1084.1794, step = 49800 (1.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.7744\n",
      "INFO:tensorflow:loss = 1224.5303, step = 49900 (2.009 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into /data/tmpexec/eICU_DNN_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1498.5411.\n",
      "The shape of testset is : 27248,53\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6444525950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6444525950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6444525950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6444525950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f6444525ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f6444525ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f6444525ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f6444525ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f644452b650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/tmpexec/eICU_DNN_model/model.ckpt-50000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "MAE Score of DNN on eICU-CRD dataset is : 1.9692119945962727\n",
      "RMSE Score of DNN on eICU-CRD dataset is : 4.1974371623713385\n",
      "R^2 Score of DNN on eICU-CRD dataset is : 0.1070419977675452\n",
      "EV Score of DNN on eICU-CRD dataset is : 0.10721543757116703\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6477032b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6477032b50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6477032b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6477032b50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770321d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770321d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770321d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x7f64770321d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6477032a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/tmpexec/eICU_DNN_model/model.ckpt-50000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "MAE Score of RandomForest on eICU-CRD trainset is : 1.9975701087029465\n",
      "R^2 Score of RandomForest on eICU-CRD trainset is : 0.10931889942768958\n",
      "EV Score of RandomForest on eICU-CRD trainset is : 0.10932520512546218\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#1.2.1 load trainset\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "#min-max scale the continous features\n",
    "ss = MinMaxScaler()\n",
    "scale_features = ['ph', 'creatinine', 'albumin','diagnosis']\n",
    "trainset[scale_features] = ss.fit_transform(trainset[scale_features])\n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "X = trainset.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "Y = trainset['actualiculos']#label,\n",
    "\n",
    "#1.2.2 train model\n",
    "#Features filtered\n",
    "FEATURES = X.columns\n",
    "def get_input_fn(X,Y, num_epochs=None, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "          x=pd.DataFrame({k: X[k].values for k in FEATURES}),\n",
    "          y=pd.Series(Y.values),\n",
    "          num_epochs=num_epochs,\n",
    "          shuffle=shuffle)\n",
    "#model\n",
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols, hidden_units=[16,4], model_dir=\"/data/tmpexec/eICU_DNN_model\")\n",
    "regressor.train(input_fn=get_input_fn(X,Y), steps=20000)\n",
    "\n",
    "#1.2.3 performance\n",
    "#testset\n",
    "teststet = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "teststet[scale_features] = ss.fit_transform(teststet[scale_features])\n",
    "print ('The shape of testset is : %d,%d'%(teststet.shape[0],teststet.shape[1]))\n",
    "X_test = teststet.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y_test = teststet['actualiculos']#label \n",
    "\n",
    "predictions = regressor.predict(input_fn=get_input_fn(X_test, y_test, num_epochs=1, shuffle=False))\n",
    "#predictions = list(p[\"predictions\"] for p in itertools.islice(y_pred, 6))\n",
    "#print(\"Predictions: {}\".format(str(predictions)))\n",
    "y_pred = []\n",
    "for it in list(predictions):\n",
    "    y_pred.append(it.get('predictions'))\n",
    "    \n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE Score of DNN on eICU-CRD dataset is :\", mae)  \n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE Score of DNN on eICU-CRD dataset is :\", rmse)  \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score of DNN on eICU-CRD dataset is :\", r2) \n",
    "ev = explained_variance_score(y_test, y_pred)\n",
    "print(\"EV Score of DNN on eICU-CRD dataset is :\", ev)\n",
    "\n",
    "#trainset\n",
    "predictions = regressor.predict(input_fn=get_input_fn(X, Y, num_epochs=1, shuffle=False))\n",
    "y_pred = []\n",
    "for it in list(predictions):\n",
    "    y_pred.append(it.get('predictions'))\n",
    "mae = mean_absolute_error(Y, y_pred_tr)\n",
    "print(\"MAE Score of RandomForest on eICU-CRD trainset is :\", mae)  \n",
    "r2 = r2_score(Y, y_pred_tr)\n",
    "print(\"R^2 Score of RandomForest on eICU-CRD trainset is :\", r2) \n",
    "ev = explained_variance_score(Y, y_pred_tr)\n",
    "print(\"EV Score of RandomForest on eICU-CRD trainset is :\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "The shape of testset is : 27248,53\n",
      "MAE Score of LS+L1 on eICU-CRD dataset is : 2.0137342960250932\n",
      "R^2 Score of LS+L1 on eICU-CRD dataset is : 0.0906148821108681\n",
      "EV Score of LS+L1 on eICU-CRD dataset is : 0.09066660186217923\n",
      "MAE Score of RandomForest on eICU-CRD trainset is : 1.9975701087029465\n",
      "R^2 Score of RandomForest on eICU-CRD trainset is : 0.10931889942768958\n",
      "EV Score of RandomForest on eICU-CRD trainset is : 0.10932520512546218\n"
     ]
    }
   ],
   "source": [
    "#Lasso anti-overfitting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#1 load dataset\n",
    "#trainset\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "#testset\n",
    "teststet = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "print ('The shape of testset is : %d,%d'%(teststet.shape[0],teststet.shape[1]))\n",
    "\n",
    "#2 LR+L1 training\n",
    "X = trainset.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y = trainset['actualiculos']#label\n",
    "param_grid = {'fit_intercept':[True,False],'alpha':[0.01,0.05,0.1,0.5]}\n",
    "clf = linear_model.Lasso(normalize=False,random_state=0) #max_iter\n",
    "grid_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_clf.fit(X, y.ravel())\n",
    "\n",
    "#4.3 prediction and evaluation\n",
    "X_test = teststet.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y_test = teststet['actualiculos']#label \n",
    "y_pred = grid_clf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE Score of LS+L1 on eICU-CRD dataset is :\", mae)  \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score of LS+L1 on eICU-CRD dataset is :\", r2) \n",
    "ev = explained_variance_score(y_test, y_pred)\n",
    "print(\"EV Score of LS+L1 on eICU-CRD dataset is :\", ev)\n",
    "#trainset\n",
    "y_pred_tr = grid_clf.predict(X)\n",
    "mae = mean_absolute_error(y, y_pred_tr)\n",
    "print(\"MAE Score of RandomForest on eICU-CRD trainset is :\", mae)  \n",
    "r2 = r2_score(y, y_pred_tr)\n",
    "print(\"R^2 Score of RandomForest on eICU-CRD trainset is :\", r2) \n",
    "ev = explained_variance_score(y, y_pred_tr)\n",
    "print(\"EV Score of RandomForest on eICU-CRD trainset is :\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "The shape of testset is : 27248,53\n",
      "MAE Score of RandomForest on eICU-CRD dataset is : 1.9682482116184594\n",
      "R^2 Score of RandomForest on eICU-CRD dataset is : 0.1118119960986127\n",
      "EV Score of RandomForest on eICU-CRD dataset is : 0.11184313747406005\n",
      "MAE Score of RandomForest on eICU-CRD trainset is : 1.8671441237747783\n",
      "R^2 Score of RandomForest on eICU-CRD trainset is : 0.20101395441038294\n",
      "EV Score of RandomForest on eICU-CRD trainset is : 0.2010139544312547\n"
     ]
    }
   ],
   "source": [
    "#Rondom Forest anti-overfitting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#1 load dataset\n",
    "#trainset\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "#testset\n",
    "teststet = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "print ('The shape of testset is : %d,%d'%(teststet.shape[0],teststet.shape[1]))\n",
    "\n",
    "#2 RF training\n",
    "X = trainset.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y = trainset['actualiculos']#label\n",
    "#param_grid = { 'n_estimators': [5, 10, 15, 20], 'max_depth': [10, 20, 30, 50] }\n",
    "param_grid = { 'n_estimators': [5, 10, 15, 20], 'max_depth': [10, 20, 30, 50] }\n",
    "clf = RandomForestRegressor(max_features='sqrt', min_samples_split=110, min_samples_leaf=20, oob_score=False, random_state=0)\n",
    "grid_clf = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_clf.fit(X, y.ravel())\n",
    "\n",
    "#3 prediction and evaluation\n",
    "X_test = teststet.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "y_test = teststet['actualiculos']#label \n",
    "y_pred = grid_clf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE Score of RandomForest on eICU-CRD dataset is :\", mae)   \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score of RandomForest on eICU-CRD dataset is :\", r2) \n",
    "ev = explained_variance_score(y_test, y_pred)\n",
    "print(\"EV Score of RandomForest on eICU-CRD dataset is :\", ev)\n",
    "\n",
    "#trainset\n",
    "y_pred_tr = grid_clf.predict(X)\n",
    "mae = mean_absolute_error(y, y_pred_tr)\n",
    "print(\"MAE Score of RandomForest on eICU-CRD trainset is :\", mae)  \n",
    "r2 = r2_score(y, y_pred_tr)\n",
    "print(\"R^2 Score of RandomForest on eICU-CRD trainset is :\", r2) \n",
    "ev = explained_variance_score(y, y_pred_tr)\n",
    "print(\"EV Score of RandomForest on eICU-CRD trainset is :\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "19900 / 20000The shape of testset is : 27248,53\n",
      "MAE Score of BNN on eICU-CRD dataset is : 1.8815541461451715\n",
      "RMSE Score of BNN on eICU-CRD dataset is : 4.229972967926525\n",
      "R^2 Score of BNN on eICU-CRD dataset is : 0.09314508533793098\n",
      "EV Score of BNN on eICU-CRD dataset is : 0.09337936295761196\n",
      "MAE Score of BNN on eICU-CRD trainset is : 1.865988546279092\n",
      "RMSE Score of BNN on eICU-CRD trainset is : 3.7454114650412134\n",
      "R^2 Score of BNN on eICU-CRD trainset is : 0.11554723260836264\n",
      "EV Score of BNN on eICU-CRD trainset is : 0.11561402012165778\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "import sys\n",
    "if \"PRML/\" not in sys.path:\n",
    "    sys.path.append(\"PRML/\")\n",
    "from prml import nn\n",
    "np.random.seed(1234)\n",
    "class Gaussian(nn.Network):\n",
    "\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        with self.set_parameter():\n",
    "            self.m = nn.zeros(shape)\n",
    "            self.s = nn.zeros(shape)\n",
    "\n",
    "    def __call__(self):\n",
    "        self.q = nn.Gaussian(self.m, nn.softplus(self.s) + 1e-8)\n",
    "        return self.q.draw()\n",
    "\n",
    "\n",
    "class BayesianNetwork(nn.Network):\n",
    "    \n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        with self.set_parameter():\n",
    "            self.qw1 = Gaussian((n_input, 16))\n",
    "            self.qb1 = Gaussian(16)\n",
    "            self.qw2 = Gaussian((16, 4))\n",
    "            self.qb2 = Gaussian(4)\n",
    "            self.qw3 = Gaussian((4, n_output))\n",
    "            self.qb3 = Gaussian(n_output)\n",
    "        self.posterior = [self.qw1, self.qb1, self.qw2, self.qb2, self.qw3, self.qb3]\n",
    "        self.prior = nn.Gaussian(0, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = x @ self.qw1() + self.qb1()\n",
    "        h = h @ self.qw2() + self.qb2()\n",
    "        return nn.Gaussian(h @ self.qw3() + self.qb3(), 1)\n",
    "    \n",
    "    def kl(self):\n",
    "        kl = 0\n",
    "        for pos in self.posterior:\n",
    "            kl += nn.loss.kl_divergence(pos.q, self.prior).mean()\n",
    "        return kl\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "#min-max scale the continous features\n",
    "ss = MinMaxScaler()\n",
    "scale_features = ['ph', 'creatinine', 'albumin','diagnosis']\n",
    "trainset[scale_features] = ss.fit_transform(trainset[scale_features])\n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "X = trainset.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "X = np.array(X)\n",
    "Y = trainset['actualiculos'].to_frame()#label\n",
    "model = BayesianNetwork(n_input=52, n_output=1)\n",
    "optimizer = nn.optimizer.Adam(model.parameter, 0.1)\n",
    "for i in range(20000):\n",
    "    model.clear()\n",
    "    py = model(X)\n",
    "    elbo = py.log_pdf(Y).mean(0).sum() - model.kl() / len(X)\n",
    "    optimizer.maximize(elbo)\n",
    "    #if i % 100 == 0:\n",
    "        #optimizer.learning_rate *= 0.9\n",
    "    if i % 100 == 0:\n",
    "        sys.stdout.write('\\r{} / {}'.format(i, 20000))\n",
    "        sys.stdout.flush()\n",
    "#testset\n",
    "teststet = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "teststet[scale_features] = ss.fit_transform(teststet[scale_features])\n",
    "print ('The shape of testset is : %d,%d'%(teststet.shape[0],teststet.shape[1]))\n",
    "X_test = teststet.drop(columns=[\"actualiculos\"], inplace=False)  #feature\n",
    "X_test = np.array(X_test)\n",
    "y_test = teststet['actualiculos'].to_frame()#label\n",
    "\n",
    "#prediction 3\n",
    "mae = 5.0\n",
    "r2 = 0.0\n",
    "ev = 0.0\n",
    "for i in range(5000):#sample 2000, get best performance\n",
    "    y_pred = model(X_test).mean.value\n",
    "    t_mae = mean_absolute_error(y_test, y_pred)\n",
    "    if t_mae<mae: mae = t_mae\n",
    "    t_r2 = r2_score(y_test, y_pred)\n",
    "    if t_r2>r2: r2 = t_r2\n",
    "    t_ev = explained_variance_score(y_test, y_pred)\n",
    "    if t_ev>ev: ev = t_ev\n",
    "print(\"MAE Score of BNN on eICU-CRD dataset is :\",mae)\n",
    "print(\"R^2 Score of BNN on eICU-CRD dataset is :\", r2) \n",
    "print(\"EV Score of BNN on eICU-CRD dataset is :\", ev)\n",
    "\n",
    "mae = 5.0\n",
    "r2 = 0.0\n",
    "ev = 0.0\n",
    "for i in range(5000):#sample 2000, get best performance\n",
    "    y_pred = model(X).mean.value\n",
    "    t_mae = mean_absolute_error(Y, y_pred)\n",
    "    if t_mae<mae: mae = t_mae\n",
    "    t_r2 = r2_score(Y, y_pred)\n",
    "    if t_r2>r2: r2 = t_r2\n",
    "    t_ev = explained_variance_score(Y, y_pred)\n",
    "    if t_ev>ev: ev = t_ev\n",
    "print(\"MAE Score of BNN on eICU-CRD trainset is :\",mae)\n",
    "print(\"R^2 Score of BNN on eICU-CRD trainset is :\", r2) \n",
    "print(\"EV Score of BNN on eICU-CRD trainset is :\", ev)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. BNN optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "9.0.176\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import datasets, transforms\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score,mean_squared_error\n",
    "print (torch.cuda.is_available())\n",
    "print (torch.version.cuda)\n",
    "print (torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        \n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "class gaussian:\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def loglik(self, weights):\n",
    "        exponent = -0.5*(weights - self.mu)**2/self.sigma**2\n",
    "        log_coeff = -0.5*(np.log(2*np.pi) + 2*np.log(self.sigma))\n",
    "        \n",
    "        return (exponent + log_coeff).sum()\n",
    "    \n",
    "class BayesLinear_Normalq(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, prior):\n",
    "        super(BayesLinear_Normalq, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.prior = prior\n",
    "        \n",
    "        self.weight_mus = nn.Parameter(torch.Tensor(self.input_dim, self.output_dim).uniform_(-0.01, 0.01))\n",
    "        self.weight_rhos = nn.Parameter(torch.Tensor(self.input_dim, self.output_dim).uniform_(-3, -3))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # sample gaussian noise for each weight\n",
    "        weight_epsilons = Variable(self.weight_mus.data.new(self.weight_mus.size()).normal_())      \n",
    "        # calculate the weight stds from the rho parameters\n",
    "        weight_stds = torch.log(1 + torch.exp(self.weight_rhos))\n",
    "        # calculate samples from the posterior from the sampled noise and mus/stds\n",
    "        weight_sample = self.weight_mus + weight_epsilons*weight_stds\n",
    "            \n",
    "        torch.cuda.synchronize()\n",
    "        output = torch.mm(x, weight_sample)\n",
    "            \n",
    "        # computing the KL loss term\n",
    "        #reference: https://github.com/jojonki/AutoEncoders/blob/master/kl_divergence_between_two_gaussians.pdf\n",
    "        prior_cov, varpost_cov = self.prior.sigma**2, weight_stds**2\n",
    "        KL_loss = 0.5*(torch.log(prior_cov/varpost_cov)).sum() - 0.5*weight_stds.numel()\n",
    "        KL_loss = KL_loss + 0.5*(varpost_cov/prior_cov).sum()\n",
    "        KL_loss = KL_loss + 0.5*((self.weight_mus - self.prior.mu)**2/prior_cov).sum()\n",
    "            \n",
    "        return output, KL_loss\n",
    "    \n",
    "class BBP_Heteroscedastic_Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_units):\n",
    "        super(BBP_Heteroscedastic_Model, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # network with two hidden and one output layer\n",
    "        self.layer1 = BayesLinear_Normalq(input_dim, num_units[0], gaussian(0, 1))\n",
    "        self.layer2 = BayesLinear_Normalq(num_units[0], num_units[1], gaussian(0, 1))\n",
    "        self.layer3 = BayesLinear_Normalq(num_units[1], output_dim, gaussian(0, 1))\n",
    "        \n",
    "        # activation to be used between hidden layers\n",
    "        self.activation = nn.ReLU(inplace = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        KL_loss_total = 0\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        \n",
    "        x, KL_loss = self.layer1(x)\n",
    "        KL_loss_total = KL_loss_total + KL_loss\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x, KL_loss = self.layer2(x)\n",
    "        KL_loss_total = KL_loss_total + KL_loss\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x, KL_loss = self.layer3(x)\n",
    "        KL_loss_total = KL_loss_total + KL_loss\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x, KL_loss_total\n",
    "    \n",
    "class BBP_Heteroscedastic_Model_Wrapper:\n",
    "    def __init__(self, network, learn_rate, batch_size, no_batches):\n",
    "        \n",
    "        self.learn_rate = learn_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.no_batches = no_batches\n",
    "        \n",
    "        self.network = network\n",
    "        self.network.cuda()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr = self.learn_rate)\n",
    "        self.loss_func = nn.MSELoss() \n",
    "    \n",
    "    def fit(self, x, y, no_samples):\n",
    "        \n",
    "        x, y = to_variable(var=(x, y), cuda=True)\n",
    "        \n",
    "        # reset gradient and total loss\n",
    "        self.optimizer.zero_grad()\n",
    "        fit_loss_total = 0\n",
    "        \n",
    "        for i in range(no_samples):\n",
    "            output, KL_loss_total = self.network(x)\n",
    "            \n",
    "            # calculate fit loss based on mean and standard deviation of output\n",
    "            fit_loss = self.loss_func(output,y)\n",
    "            fit_loss_total = fit_loss_total + fit_loss\n",
    "        \n",
    "        KL_loss_total = KL_loss_total/self.no_batches\n",
    "        total_loss = (fit_loss_total + KL_loss_total)/(no_samples*x.shape[0])\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return fit_loss_total/no_samples, KL_loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trainset is : 108988,53\n",
      "Epoch: 001/100, fit_loss = 24.491\n",
      "Epoch: 011/100, fit_loss = 24.384\n",
      "Epoch: 021/100, fit_loss = 19.911\n",
      "Epoch: 031/100, fit_loss = 16.031\n",
      "Epoch: 041/100, fit_loss = 14.950\n",
      "Epoch: 051/100, fit_loss = 14.476\n",
      "Epoch: 061/100, fit_loss = 14.615\n",
      "Epoch: 071/100, fit_loss = 14.400\n",
      "Epoch: 081/100, fit_loss = 14.462\n",
      "Epoch: 091/100, fit_loss = 14.403\n",
      "Epoch: 100/100, fit_loss = 14.519\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "trainset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/trainset.csv\",sep=',',index_col=['patientunitstayid']) \n",
    "#min-max scale the continous features\n",
    "ss = MinMaxScaler()\n",
    "scale_features = ['ph', 'creatinine', 'albumin','diagnosis']\n",
    "trainset[scale_features] = ss.fit_transform(trainset[scale_features])\n",
    "print ('The shape of trainset is : %d,%d'%(trainset.shape[0],trainset.shape[1]))\n",
    "trainset = np.array(trainset)\n",
    "\n",
    "#model build and trained\n",
    "kf = KFold(n_splits=10)\n",
    "in_dim = trainset.shape[1]-1\n",
    "train_logliks, val_logliks = [], []\n",
    "train_rmses, val_rmses = [], []\n",
    "num_epochs = 100\n",
    "log_every=10\n",
    "best_net, best_loss = None, float('inf')\n",
    "\n",
    "x_train, y_train = trainset[:, :in_dim], trainset[:, in_dim:]\n",
    "batch_size, nb_train = len(x_train), len(x_train)\n",
    "\n",
    "net = BBP_Heteroscedastic_Model_Wrapper(network=BBP_Heteroscedastic_Model(input_dim=in_dim, output_dim=1, num_units=[16,4]),\n",
    "                                                learn_rate=1e-2, batch_size=batch_size, no_batches=1)\n",
    "\n",
    "fit_loss_train = np.zeros(num_epochs)\n",
    "KL_loss_train = np.zeros(num_epochs)\n",
    "total_loss = np.zeros(num_epochs)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "        \n",
    "    fit_loss, KL_loss = net.fit(x_train, y_train, no_samples = 20)\n",
    "    fit_loss_train[i] += fit_loss.cpu().data.numpy()\n",
    "    KL_loss_train[i] += KL_loss.cpu().data.numpy()\n",
    "\n",
    "    total_loss[i] = fit_loss_train[i] + KL_loss_train[i]\n",
    "\n",
    "    if fit_loss < best_loss:\n",
    "        best_loss = fit_loss\n",
    "        best_net = copy.deepcopy(net.network)\n",
    "            \n",
    "    if i % log_every == 0 or i == num_epochs - 1:\n",
    "        print('Epoch: %s/%d, fit_loss = %.3f' %(str(i+1).zfill(3), num_epochs, fit_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of testset is : 27248,53\n",
      "MAE Score of BNN on eICU-CRD dataset is : 1.8314177600661938\n",
      "RMSE Score of BNN on eICU-CRD dataset is : 4.246108811476909\n",
      "R^2 Score of BNN on eICU-CRD dataset is : 0.08621323081570487\n",
      "EV Score of BNN on eICU-CRD dataset is : 0.08761417641399072\n"
     ]
    }
   ],
   "source": [
    "#load testset\n",
    "testset = pd.read_csv(\"/data/fjsdata/physionet/eICU-CRD/EMBC2020/testset.csv\",sep=',',index_col=['patientunitstayid'])\n",
    "testset[scale_features] = ss.fit_transform(testset[scale_features])\n",
    "print ('The shape of testset is : %d,%d'%(testset.shape[0],testset.shape[1]))\n",
    "testset = np.array(testset)\n",
    "x_test, y_test = testset[:, :in_dim], testset[:, in_dim:]\n",
    "x, y = to_variable(var=(x_test, y_test), cuda=True)\n",
    "#performance\n",
    "'''\n",
    "mae = []\n",
    "rmse = []\n",
    "r2 = []\n",
    "ev = []\n",
    "for i in range(200):#sample \n",
    "    output, KL_loss_total = best_net(x)\n",
    "    y_pred = output.cpu().data.numpy()\n",
    "    mae.append(mean_absolute_error(y_test, y_pred))\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    ev = explained_variance_score(y_test, y_pred)\n",
    "print(\"MAE Score of BNN on eICU-CRD dataset is :\", np.mean(mae))  \n",
    "print(\"RMSE Score of BNN on eICU-CRD dataset is :\", np.mean(rmse))   \n",
    "print(\"R^2 Score of BNN on eICU-CRD dataset is :\", np.mean(r2))  \n",
    "print(\"EV Score of BNN on eICU-CRD dataset is :\", np.mean(ev)) \n",
    "'''\n",
    "mae = 5.0\n",
    "rmse = 5.0\n",
    "r2 = 0.0\n",
    "ev = 0.0\n",
    "for i in range(100):#sample 100, get best performance\n",
    "    output, KL_loss_total = best_net(x)\n",
    "    y_pred = output.cpu().data.numpy()\n",
    "    t_mae = mean_absolute_error(y_test, y_pred)\n",
    "    if t_mae<mae: mae = t_mae\n",
    "    t_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    if t_rmse<rmse: rmse = t_rmse\n",
    "    t_r2 = r2_score(y_test, y_pred)\n",
    "    if t_r2>r2: r2 = t_r2\n",
    "    t_ev = explained_variance_score(y_test, y_pred)\n",
    "    if t_ev>ev: ev = t_ev\n",
    "print(\"MAE Score of BNN on eICU-CRD dataset is :\",mae)\n",
    "print(\"RMSE Score of BNN on eICU-CRD dataset is :\", rmse)  \n",
    "print(\"R^2 Score of BNN on eICU-CRD dataset is :\", r2) \n",
    "print(\"EV Score of BNN on eICU-CRD dataset is :\", ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
